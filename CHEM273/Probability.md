# Probability Theory Basics

1. Axioms of Probability
* Heuristic explanation => more mathematical rigorous: see Cox's theorem
  - [Skat Thuringia](https://en.wikipedia.org/wiki/Skat_(card_game))
  - Probability P that we observe an event e_i, given, it occurred
  - P(observe|e_i)
  - If events are mutually exclusive: 3rd axiom
  - Be careful if events are not mutually exclusive (like a set of events or a sequence of events)

2. Conditional Probabilities and Bayes Theorem
* Bayes Theorem
* Marginalization
* PlotPD_Plus.py
  - Statement 1: Sensitivity
  - Statement 2: prior
  - Statement 3: p-value or false positive rate

3. Information and Entropy
* low entropy vs high entropy
* Data analysis
  - image processing
  - noise reduction
  - feature detection
* Biophysics
  - molecular driving forces
  - formation of macromolecules
  - "ordering forces"
* AI
  - optimization
  - cross entropy
* statistics/information theory
  - maximum entropy, given constrains
* entropy S is a measure of information we have about a system
* entropy is important in statistics, physics, informatic etc
  - important: entropy has nothing to do with order/disorder

